{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import mean\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"train.csv\")\n",
    "#df1.head()\n",
    "df2 = pd.read_csv('test.csv')\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from df1 drop sub_are\n",
    "df1 = df1.drop(columns=['sub_area'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from df2 drop sub_area and row ID \n",
    "df2 = df2.drop(columns=['sub_area', 'row ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(columns=[ 'row ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poselenie Shhapovskoe             1105\n",
      "Alekseevskoe                      1104\n",
      "Tverskoe                          1101\n",
      "Poselenie Mosrentgen              1099\n",
      "Caricyno                          1097\n",
      "                                  ... \n",
      "Posleenie Novofedorovskoe            3\n",
      "Poseleine Voronovskoe                3\n",
      "Poselenie Mhiajlovo-Jarcevskoe       3\n",
      "Prsopekt Vernadskogo                 2\n",
      "Poselenie Krasnopahorksoe            2\n",
      "Name: sub_area, Length: 1927, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "category_frequencies = df1['sub_area'].value_counts()\n",
    "\n",
    "print(category_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781\n",
      "1927\n"
     ]
    }
   ],
   "source": [
    "infrequent_categories = category_frequencies[category_frequencies < 900].index.tolist()\n",
    "print(len(infrequent_categories))\n",
    "print(len(category_frequencies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "df1['sub_area'] = df1['sub_area'].replace(infrequent_categories, 'Other')\n",
    "df2['sub_area'] = df2['sub_area'].replace(infrequent_categories, 'Other')\n",
    "category_frequencies1 = df1['sub_area'].value_counts()\n",
    "print(len(category_frequencies1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot = pd.get_dummies(df1)\n",
    "df_onehot.dtypes\n",
    "test_onehot = pd.get_dummies(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "categorical_cols = df1.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_colstest = df2.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# You can also encode labels to identify categorical columns\n",
    "for col in categorical_cols:\n",
    "    df1[col] = label_encoder.fit_transform(df1[col])\n",
    "\n",
    "for col in categorical_colstest:\n",
    "    df2[col] = label_encoder.fit_transform(df2[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_onehot.drop(columns=['price_doc'])\n",
    "print(X.shape)\n",
    "y = df_onehot[['price_doc']]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181507, 271)\n"
     ]
    }
   ],
   "source": [
    "X = df1.drop(columns=['price_doc'])\n",
    "print(X.shape)\n",
    "y = df1[['price_doc']]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_testscaled = scaler.fit_transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop row id from x_testscaled\n",
    "X_testscaled = X_testscaled[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_testscaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covert x_scaled to dataframe\n",
    "X_scaled = pd.DataFrame(X_scaled)\n",
    "#convert x_testscaled to dataframe\n",
    "X_testscaled = pd.DataFrame(X_testscaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testscaled = X_testscaled[X_scaled.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "n_components = 150  # You can choose the number of components based on your requirements\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Apply PCA to the training data\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Apply the same PCA transformation to the test data\n",
    "df2_onehot_pca = pca.transform(X_testscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77789, 150)\n"
     ]
    }
   ],
   "source": [
    "print(df2_onehot_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['x0' 'x1' 'x3' 'x4' 'x7' 'x9' 'x10' 'x15' 'x16' 'x17' 'x21' 'x22' 'x23'\n",
      " 'x31' 'x36' 'x41' 'x48' 'x70' 'x74' 'x86' 'x87' 'x99' 'x101' 'x128'\n",
      " 'x134']\n"
     ]
    }
   ],
   "source": [
    "ols_reg = LinearRegression()\n",
    "sfs = SequentialFeatureSelector(ols_reg, direction='forward', n_features_to_select=25,n_jobs=-1)\n",
    "sfs.fit(X_pca, y)\n",
    "#X_selected = sfs.transform(X_pca)\n",
    "# Print the names of the selected features\n",
    "print(\"Selected Features:\", sfs.get_feature_names_out())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the selected features in a dataframe\n",
    "X_selected = pd.DataFrame(sfs.transform(X_pca), columns=sfs.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the selected features in a dataframe\n",
    "X_testselected = pd.DataFrame(sfs.transform(df2_onehot_pca), columns=sfs.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181507, 25)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77789, 25)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testselected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['x101', 'x128', 'x134'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32me:\\Challenge 2\\Linear_reg_Poly_inter.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Challenge%202/Linear_reg_Poly_inter.ipynb#Y105sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_testscaled \u001b[39m=\u001b[39m X_testscaled[X_selected\u001b[39m.\u001b[39;49mcolumns]\n",
      "File \u001b[1;32mc:\\Users\\anfam\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\anfam\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anfam\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['x101', 'x128', 'x134'] not in index\""
     ]
    }
   ],
   "source": [
    "X_testscaled = X_testscaled[X_selected.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_testscaled.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['x101', 'x128', 'x134'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32me:\\Challenge 2\\Linear_reg_Poly_inter.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Challenge%202/Linear_reg_Poly_inter.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m selected_feature_names \u001b[39m=\u001b[39m sfs\u001b[39m.\u001b[39mget_feature_names_out()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Challenge%202/Linear_reg_Poly_inter.ipynb#X34sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Filter columns in X_testscaled based on selected features\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Challenge%202/Linear_reg_Poly_inter.ipynb#X34sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m X_testselected \u001b[39m=\u001b[39m X_testscaled[selected_feature_names]\n",
      "File \u001b[1;32mc:\\Users\\anfam\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\anfam\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anfam\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['x101', 'x128', 'x134'] not in index\""
     ]
    }
   ],
   "source": [
    "# Create a mapping dictionary for the old column names to the new names\n",
    "column_mapping = {i: f'x{i}' for i in range(100)}\n",
    "\n",
    "# Rename the columns in X_testscaled\n",
    "X_testscaled.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = sfs.get_feature_names_out()\n",
    "\n",
    "# Filter columns in X_testscaled based on selected features\n",
    "X_testselected = X_testscaled[selected_feature_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covert x_scaled to dataframe\n",
    "X_scaled = pd.DataFrame(X_pca)\n",
    "#convert x_testscaled to dataframe\n",
    "X_testscaled = pd.DataFrame(df2_onehot_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_testselected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give me code for feature importance using linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_scaled, y)\n",
    "# get importance\n",
    "importance = model.coef_[0]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# drop features with low importance\n",
    "threshold = 70000  # Adjust the threshold as needed\n",
    "selected_features = [feature for feature, score in zip(X_scaled.columns, importance) if score >= threshold]\n",
    "X_selected = X_scaled[selected_features]\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "# Convert scaled_df1 to a DataFrame without specifying columns\n",
    "\n",
    "# Add a constant term to the feature matrix\n",
    "X_with_const = sm.add_constant(X_scaled)\n",
    "\n",
    "# Fit a linear regression model\n",
    "model = sm.OLS(y, X_with_const).fit()\n",
    "\n",
    "# Get p-values for each feature\n",
    "p_values = model.pvalues[1:]  # Exclude the constant term\n",
    "\n",
    "# Set your desired threshold for p-value\n",
    "threshold = 0.05\n",
    "\n",
    "# Filter features based on p-value\n",
    "selected_features = p_values[p_values < threshold].index\n",
    "\n",
    "# Display selected features\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Select columns in the DataFrame\n",
    "X_selected = X_scaled[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_feature_indices = np.arange(X.shape[1])\n",
    "threshold_value = 0.001\n",
    "variance_filter = VarianceThreshold(threshold=threshold_value)\n",
    "\n",
    "# Fit and transform the feature matrix\n",
    "X_filtered = variance_filter.fit_transform(X_pca)\n",
    "\n",
    "X_test_high_variance = variance_filter.transform(df2_onehot_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_testscaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_selected.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_high_variance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store x_filtered as a df\n",
    "X_filtered = pd.DataFrame(X_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected = pd.DataFrame(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep those columns in X_testscaled that are in X_selected\n",
    "X_testscaled = X_testscaled[X_selected.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure column names are trimmed\n",
    "\n",
    "# Find the common columns\n",
    "common_columns = X_testscaled.columns.intersection(X_selected.columns)\n",
    "\n",
    "# Keep only the common columns in X_testscaled\n",
    "X_testscaled_filtered = X_testscaled[common_columns]\n",
    "\n",
    "# Now X_testscaled_filtered contains only the columns that are in both X_testscaled and X_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns = X_testscaled.columns.intersection(X_selected.columns)\n",
    "X_testscaled = X_testscaled[common_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_testscaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the common column names between X_testselected and X_selected\n",
    "common_columns = X_testscaled.columns.intersection(X_selected.columns)\n",
    "\n",
    "# Keep only the common columns in X_testselected\n",
    "X_testselected = X_testscaled[X_selected.columns.intersection(common_columns)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_testselected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_testscaled_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "test_scaled = scaler.transform(test_onehot)\n",
    "print(test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Set Info:\")\n",
    "print(X.info())\n",
    "\n",
    "print(\"\\nTest Set Info:\")\n",
    "print(test_onehot.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181507, 2626)\n",
      "['1' 'x0' 'x1' ... 'x99 x101 x134' 'x99 x128 x134' 'x101 x128 x134']\n",
      "0.6657085569351444\n",
      "[[-1.73162865e-08  2.98909053e+05 -2.02469769e+05 ...  3.40440340e+04\n",
      "   7.85579495e+03 -1.45958274e+04]]\n",
      "[16438256.0858673]\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(3, interaction_only=True)\n",
    "X2 = poly.fit_transform(X_selected)\n",
    "test2 = poly.fit_transform(X_testselected)\n",
    "print(X2.shape)\n",
    "print(poly.get_feature_names_out())\n",
    "reg2 = LinearRegression().fit(X2, y)\n",
    "print(reg2.score(X2, y))\n",
    "print(reg2.coef_)\n",
    "print(reg2.intercept_)\n",
    "md_probs = reg2.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Create a DataFrame with 'row ID' and predicted values\n",
    "predicted_df = pd.DataFrame({\n",
    "    'row ID': additional_data['row ID'],\n",
    "    'price_doc': md_probs[:,0]  # Replace with the actual column name for your predictions\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "predicted_df.to_csv('predictions36.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
