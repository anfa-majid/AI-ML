{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"train.csv\")\n",
    "#df1.head()\n",
    "df2 = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "categorical_cols = df1.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_colstest = df2.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# You can also encode labels to identify categorical columns\n",
    "for col in categorical_cols:\n",
    "    df1[col] = label_encoder.fit_transform(df1[col])\n",
    "\n",
    "for col in categorical_colstest:\n",
    "    df2[col] = label_encoder.fit_transform(df2[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_onehot = pd.get_dummies(df1,)\n",
    "df2_onehot = pd.get_dummies(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_onehot = pd.get_dummies(df1,drop_first='true')\n",
    "df2_onehot = pd.get_dummies(df2,drop_first= 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns = df1_onehot.columns.intersection(df2_onehot.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1_onehot.loc[:, df1_onehot.columns != 'price_doc']\n",
    "y = df1_onehot[['price_doc']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1_onehot[['price_doc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df1_onehot[common_columns]\n",
    "X_test = df2_onehot[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_testscaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the same scaler\n",
    "X_testscaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 40  # You can choose the number of components based on your requirements\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Apply PCA to the training data\n",
    "X_pca = pca.fit_transform(X_filtered)\n",
    "\n",
    "# Apply the same PCA transformation to the test data\n",
    "df2_onehot_pca = pca.transform(X_test_high_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_feature_indices = np.arange(X.shape[1])\n",
    "threshold_value = 0.001\n",
    "variance_filter = VarianceThreshold(threshold=threshold_value)\n",
    "\n",
    "# Fit and transform the feature matrix\n",
    "X_filtered = variance_filter.fit_transform(X_scaled)\n",
    "\n",
    "X_test_high_variance = variance_filter.transform(X_testscaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_reg = LinearRegression()\n",
    "sfs = SequentialFeatureSelector(ols_reg, direction='forward', n_features_to_select=25)\n",
    "sfs.fit(X_scaled, y)\n",
    "X_selected = sfs.transform(X_scaled)\n",
    "# Print the names of the selected features\n",
    "print(\"Selected Features:\", sfs.get_feature_names_out())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_high_variance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_onehot_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = LinearRegression().fit(X_filtered, y)\n",
    "print(reg2.score(X_filtered, y))\n",
    "print(reg2.coef_)\n",
    "print(reg2.intercept_)\n",
    "md_probs = reg2.predict(X_test_high_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2, interaction_only=True)\n",
    "X2 = poly.fit_transform(X_pca)\n",
    "test2 = poly.fit_transform(df2_onehot_pca)\n",
    "print(X2.shape)\n",
    "print(poly.get_feature_names_out())\n",
    "reg2 = LinearRegression().fit(X2, y)\n",
    "print(reg2.score(X2, y))\n",
    "print(reg2.coef_)\n",
    "print(reg2.intercept_)\n",
    "md_probs = reg2.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Create a DataFrame with 'row ID' and predicted values\n",
    "predicted_df = pd.DataFrame({\n",
    "    'row ID': additional_data['row ID'],\n",
    "    'price_doc': md_probs[:,0]  # Replace with the actual column name for your predictions\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "predicted_df.to_csv('predictions28.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
